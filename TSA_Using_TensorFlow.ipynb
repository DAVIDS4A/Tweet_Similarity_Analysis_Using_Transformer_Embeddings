{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import TFBertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dtr=pd.read_csv(\"train.xlsx - Sheet1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dtr=tweet_dtr.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ladygaga</td>\n",
       "      <td>Make your reservation now. #GagaAHSHotelhttps:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ladygaga</td>\n",
       "      <td>@DrunkyViviana we shot for 3 days but planned ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ladygaga</td>\n",
       "      <td>me I'm back in the NY GROOVEpic.twitter.com/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ladygaga</td>\n",
       "      <td>GLEE WAS SO AMAZING! AH!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ladygaga</td>\n",
       "      <td>LIVE with @JoJoWright in 5 minutes on @1027KIISFM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user                                               text\n",
       "0  ladygaga  Make your reservation now. #GagaAHSHotelhttps:...\n",
       "1  ladygaga  @DrunkyViviana we shot for 3 days but planned ...\n",
       "2  ladygaga   me I'm back in the NY GROOVEpic.twitter.com/c...\n",
       "3  ladygaga                        GLEE WAS SO AMAZING! AH!!!!\n",
       "4  ladygaga  LIVE with @JoJoWright in 5 minutes on @1027KIISFM"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_dtr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data class distribution:\n",
      "1    10400\n",
      "0    10400\n",
      "Name: similarity_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import random\n",
    "\n",
    "# Function to sample pairs of tweets\n",
    "def sample_tweet_pairs(tweet_dtr, num_pairs):\n",
    "    same_user_pairs = []\n",
    "    diff_user_pairs = []\n",
    "\n",
    "    # Group tweets by user\n",
    "    grouped = tweet_dtr.groupby('user')\n",
    "\n",
    "    # Sampling pairs\n",
    "    for _ in range(num_pairs):\n",
    "        # Randomly select a user\n",
    "        user = random.choice(tweet_dtr['user'].unique())\n",
    "        \n",
    "        # Select two tweets from the same user\n",
    "        tweet_pair_same_user = grouped.get_group(user).sample(2, replace=False)['text'].tolist()\n",
    "        same_user_pairs.append((tweet_pair_same_user[0], tweet_pair_same_user[1], 1))\n",
    "\n",
    "        # Select two tweets from different users\n",
    "        other_users = tweet_dtr[tweet_dtr['user'] != user]\n",
    "        tweet_pair_diff_user = other_users.sample(2, replace=False)['text'].tolist()\n",
    "        diff_user_pairs.append((tweet_pair_diff_user[0], tweet_pair_diff_user[1], 0))\n",
    "\n",
    "    return same_user_pairs, diff_user_pairs\n",
    "\n",
    "# Create tweet pairs\n",
    "num_pairs = 13000  \n",
    "same_user_pairs, diff_user_pairs = sample_tweet_pairs(tweet_dtr, num_pairs)\n",
    "\n",
    "# Combine same-user and different-user pairs\n",
    "tweet_pairs = same_user_pairs + diff_user_pairs\n",
    "random.shuffle(tweet_pairs)\n",
    "\n",
    "# Convert to DataFrame\n",
    "pairs_df = pd.DataFrame(tweet_pairs, columns=['tweet1', 'tweet2', 'similarity_label'])\n",
    "\n",
    "# Stratified sampling for balanced representation\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in splitter.split(pairs_df[['tweet1', 'tweet2']], pairs_df['similarity_label']):\n",
    "    train_pairs = pairs_df.iloc[train_index]\n",
    "    test_pairs = pairs_df.iloc[test_index]\n",
    "\n",
    "# Check the balance of classes in the training data\n",
    "print(\"Training data class distribution:\")\n",
    "print(train_pairs['similarity_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet1</th>\n",
       "      <th>tweet2</th>\n",
       "      <th>similarity_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10068</th>\n",
       "      <td>Back in the studio. #confident in almost 3 hou...</td>\n",
       "      <td>me and @jaxonbieber - unstoppable! haha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>Seeing a chrome delete is what convinced me to...</td>\n",
       "      <td>Jurgen Klopp has warned his @LFC side to be wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15117</th>\n",
       "      <td>Join the President for his backyard birthday p...</td>\n",
       "      <td>If you agree that higher education is an econo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>I'm ready for all the new solar eclipse wallpa...</td>\n",
       "      <td>Fight as one, rise together !\\nThe new @Portug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13873</th>\n",
       "      <td>I met this grl that looked like Apollonia and ...</td>\n",
       "      <td>If we are not careful, we will find that knife...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet1  \\\n",
       "10068  Back in the studio. #confident in almost 3 hou...   \n",
       "1575   Seeing a chrome delete is what convinced me to...   \n",
       "15117  Join the President for his backyard birthday p...   \n",
       "2451   I'm ready for all the new solar eclipse wallpa...   \n",
       "13873  I met this grl that looked like Apollonia and ...   \n",
       "\n",
       "                                                  tweet2  similarity_label  \n",
       "10068            me and @jaxonbieber - unstoppable! haha                 1  \n",
       "1575   Jurgen Klopp has warned his @LFC side to be wa...                 0  \n",
       "15117  If you agree that higher education is an econo...                 1  \n",
       "2451   Fight as one, rise together !\\nThe new @Portug...                 0  \n",
       "13873  If we are not careful, we will find that knife...                 0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5200, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pairs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all text to lowercase\n",
    "train_pairs[\"tweet1\"] = [tweet.lower() for tweet in train_pairs[\"tweet1\"]]\n",
    "train_pairs[\"tweet2\"] = [tweet.lower() for tweet in train_pairs[\"tweet2\"]]\n",
    "\n",
    "test_pairs[\"tweet1\"] = [tweet.lower() for tweet in test_pairs[\"tweet1\"]]\n",
    "test_pairs[\"tweet2\"] = [tweet.lower() for tweet in test_pairs[\"tweet2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\NEXUS\n",
      "[nltk_data]     COMPUTERS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# removing special characters sauf hashtags and mentions\n",
    "def remove_special_chars(text):\n",
    "    # Initializing TweetTokenizer from NLTK\n",
    "    tokenizer = TweetTokenizer()\n",
    "\n",
    "    # Tokenizing the text\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    # empty list to store cleaned tokens\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    # regex pattern to remove punctuation symbols and special characters\n",
    "    pattern = r'[^a-zA-Z0-9#@]'\n",
    "\n",
    "    for token in tokens:\n",
    "        # add hashtags and mentions directly to cleaned_tokens\n",
    "        if token.startswith('#') or token.startswith('@'):\n",
    "            cleaned_tokens.append(token)\n",
    "        else:\n",
    "            # Remove special characters using regex\n",
    "            cleaned_token = re.sub(pattern, '', token)\n",
    "            # If the token is not empty after cleaning, add it to cleaned_tokens\n",
    "            if cleaned_token:\n",
    "                cleaned_tokens.append(cleaned_token)\n",
    "\n",
    "    # Join the cleaned tokens back into a single string\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs[\"tweet1\"] = [remove_special_chars(tweet) for tweet in train_pairs[\"tweet1\"]]\n",
    "train_pairs[\"tweet2\"] = [remove_special_chars(tweet) for tweet in train_pairs[\"tweet2\"]]\n",
    "\n",
    "test_pairs[\"tweet1\"] = [remove_special_chars(tweet) for tweet in test_pairs[\"tweet1\"]]\n",
    "test_pairs[\"tweet2\"] = [remove_special_chars(tweet) for tweet in test_pairs[\"tweet2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet1</th>\n",
       "      <th>tweet2</th>\n",
       "      <th>similarity_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10068</th>\n",
       "      <td>back in the studio #confident in almost 3 hour...</td>\n",
       "      <td>me and @jaxonbieber unstoppable haha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>seeing a chrome delete is what convinced me to...</td>\n",
       "      <td>jurgen klopp has warned his @lfc side to be wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15117</th>\n",
       "      <td>join the president for his backyard birthday p...</td>\n",
       "      <td>if you agree that higher education is an econo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>im ready for all the new solar eclipse wallpap...</td>\n",
       "      <td>fight as one rise together the new @portugal n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13873</th>\n",
       "      <td>i met this grl that looked like apollonia and ...</td>\n",
       "      <td>if we are not careful we will find that knife ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet1  \\\n",
       "10068  back in the studio #confident in almost 3 hour...   \n",
       "1575   seeing a chrome delete is what convinced me to...   \n",
       "15117  join the president for his backyard birthday p...   \n",
       "2451   im ready for all the new solar eclipse wallpap...   \n",
       "13873  i met this grl that looked like apollonia and ...   \n",
       "\n",
       "                                                  tweet2  similarity_label  \n",
       "10068               me and @jaxonbieber unstoppable haha                 1  \n",
       "1575   jurgen klopp has warned his @lfc side to be wa...                 0  \n",
       "15117  if you agree that higher education is an econo...                 1  \n",
       "2451   fight as one rise together the new @portugal n...                 0  \n",
       "13873  if we are not careful we will find that knife ...                 0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    #text = text.lower()\n",
    "    # Remove punctuation, symbols, etc.\n",
    "    #text = text.replace(\".\", \"\").replace(\"!\", \"\").replace(\",\", \"\").replace(\"?\", \"\")\n",
    "    # Tokenize\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "# Tokenization\n",
    "def tokenize_text(tokenizer, text):\n",
    "    return tokenizer.encode_plus(\n",
    "        text,\n",
    "        max_length=64,  # Assuming max tweet length of 64 tokens\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors='tf'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "transformer_model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "tokenized_X_train_tweet1 = [tokenize_text(tokenizer, tweet) for tweet in train_pairs['tweet1']]\n",
    "tokenized_X_train_tweet2 = [tokenize_text(tokenizer, tweet) for tweet in train_pairs['tweet2']]\n",
    "\n",
    "tokenized_X_test_tweet1 = [tokenize_text(tokenizer, tweet) for tweet in test_pairs['tweet1']]\n",
    "tokenized_X_test_tweet2 = [tokenize_text(tokenizer, tweet) for tweet in test_pairs['tweet2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL FUNC\n",
    "def build_model(transformer_model):\n",
    "    \n",
    "    # INPUT LAYER\n",
    "    input_ids1 = tf.keras.layers.Input(shape=(None,), dtype=tf.int32)\n",
    "    input_ids2 = tf.keras.layers.Input(shape=(None,), dtype=tf.int32)\n",
    "    \n",
    "    #EMBEDDING LAYER\n",
    "    embedding1 = transformer_model(input_ids1)[0][:, 0, :]\n",
    "    embedding2 = transformer_model(input_ids2)[0][:, 0, :]\n",
    "    \n",
    "    # COMPARISION USING MANHATTAN DISTANCE\n",
    "    distance = tf.keras.layers.Lambda(lambda x: tf.abs(x[0] - x[1]))([embedding1, embedding2])\n",
    "    \n",
    "    # DENSE LAYER WITH SIGMOID AS ACTIVATION FUNCTION\n",
    "    dense_layer = tf.keras.layers.Dense(1, activation='sigmoid')(distance)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[input_ids1, input_ids2], outputs=dense_layer)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the input id tensors from the tokenized list of input ids, token ids and attention mask\n",
    "inputs_1=[i['input_ids'] for i in tokenized_X_train_tweet1 ]\n",
    "inputs_2=[i['input_ids'] for i in tokenized_X_train_tweet2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the input id tensors to numpy arrays\n",
    "inputs_1_array = np.array([tensor.numpy() for tensor in inputs_1])\n",
    "inputs_2_array = np.array([tensor.numpy() for tensor in inputs_2])\n",
    "\n",
    "# Ensuring the shapes of inputs_1_array and inputs_2_array are compatible\n",
    "inputs_1_array = inputs_1_array.squeeze(axis=1)\n",
    "inputs_2_array = inputs_2_array.squeeze(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "650/650 [==============================] - 16000s 25s/step - loss: 0.7013 - accuracy: 0.4991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22e59940508>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call build_model function which returns the model into model variable\n",
    "model=build_model(transformer_model)\n",
    "\n",
    "# Train model\n",
    "model.fit([inputs_1_array, inputs_2_array], \n",
    "          train_pairs['similarity_label'], epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the input id tensors from the tokenized list of input ids, token ids and attention mask\n",
    "inputs_3=[i['input_ids'] for i in tokenized_X_test_tweet1 ]\n",
    "inputs_4=[i['input_ids'] for i in tokenized_X_test_tweet2 ]\n",
    "\n",
    "# Converting the input id tensors to numpy arrays\n",
    "inputs_3_array = np.array([tensor.numpy() for tensor in inputs_3])\n",
    "inputs_4_array = np.array([tensor.numpy() for tensor in inputs_4])\n",
    "\n",
    "# Ensuring the shapes of inputs_3_array and inputs_4_array are compatible\n",
    "inputs_3_array = inputs_3_array.squeeze(axis=1)\n",
    "inputs_4_array = inputs_4_array.squeeze(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 1275s 8s/step - loss: 0.6932 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy=model.evaluate([inputs_3_array,inputs_4_array],test_pairs['similarity_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test data csv\n",
    "tweet_dte=pd.read_csv(\"test.xlsx - Sheet1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1300, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_dte.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4930.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4619.120556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1634.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3644.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7031.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28213.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0\n",
       "count   1300.000000\n",
       "mean    4930.170000\n",
       "std     4619.120556\n",
       "min        1.000000\n",
       "25%     1634.500000\n",
       "50%     3644.000000\n",
       "75%     7031.250000\n",
       "max    28213.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_dte.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1795</td>\n",
       "      <td>ladygaga</td>\n",
       "      <td>@BarackObama thanku for the support you are se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5903</td>\n",
       "      <td>ladygaga</td>\n",
       "      <td>The first time Tom Ford and Nick Knight worked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1516</td>\n",
       "      <td>ladygaga</td>\n",
       "      <td>I feel absolutely fabulous.pic.twitter.com/NZC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5982</td>\n",
       "      <td>ladygaga</td>\n",
       "      <td>#BraveCharlie bornthiswayfoundation, an opport...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4148</td>\n",
       "      <td>ladygaga</td>\n",
       "      <td>Chipmunk Cheeks   Wisdom Teeth out before tour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      user                                               text\n",
       "0        1795  ladygaga  @BarackObama thanku for the support you are se...\n",
       "1        5903  ladygaga  The first time Tom Ford and Nick Knight worked...\n",
       "2        1516  ladygaga  I feel absolutely fabulous.pic.twitter.com/NZC...\n",
       "3        5982  ladygaga  #BraveCharlie bornthiswayfoundation, an opport...\n",
       "4        4148  ladygaga  Chipmunk Cheeks   Wisdom Teeth out before tour..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_dte.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dte=tweet_dte.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ladygaga</td>\n",
       "      <td>@BarackObama thanku for the support you are se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ladygaga</td>\n",
       "      <td>The first time Tom Ford and Nick Knight worked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ladygaga</td>\n",
       "      <td>I feel absolutely fabulous.pic.twitter.com/NZC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ladygaga</td>\n",
       "      <td>#BraveCharlie bornthiswayfoundation, an opport...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ladygaga</td>\n",
       "      <td>Chipmunk Cheeks   Wisdom Teeth out before tour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user                                               text\n",
       "0  ladygaga  @BarackObama thanku for the support you are se...\n",
       "1  ladygaga  The first time Tom Ford and Nick Knight worked...\n",
       "2  ladygaga  I feel absolutely fabulous.pic.twitter.com/NZC...\n",
       "3  ladygaga  #BraveCharlie bornthiswayfoundation, an opport...\n",
       "4  ladygaga  Chipmunk Cheeks   Wisdom Teeth out before tour..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_dte.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tweet pairs\n",
    "num_pairs = 650  \n",
    "same_user_pairs, diff_user_pairs = sample_tweet_pairs(tweet_dte, num_pairs)\n",
    "\n",
    "# Combine same-user and different-user pairs\n",
    "tweet_pairs_1 = same_user_pairs + diff_user_pairs\n",
    "random.shuffle(tweet_pairs_1)\n",
    "\n",
    "# Convert to DataFrame\n",
    "test_df = pd.DataFrame(tweet_pairs_1, columns=['tweet1', 'tweet2', 'similarity_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet1</th>\n",
       "      <th>tweet2</th>\n",
       "      <th>similarity_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>straight W's for the East leading @Raptors!\\n...</td>\n",
       "      <td>It's morrissey night! Where are you?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Final pic.twitter.com/A0xnTPUPKH</td>\n",
       "      <td>House Intelligence Committee votes to release ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You know what… you miss 100% of the shots you ...</td>\n",
       "      <td>I mean... I guess I have to give it a shot.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dishes &amp; swishes... buckets &amp; handles... @Step...</td>\n",
       "      <td>My new babies pic.twitter.com/s4ejQD6V4l</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donovan Mitchell goes coast to coast to beat t...</td>\n",
       "      <td>Had a lot of fun creating The Private Edition ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet1  \\\n",
       "0   straight W's for the East leading @Raptors!\\n...   \n",
       "1                   Final pic.twitter.com/A0xnTPUPKH   \n",
       "2  You know what… you miss 100% of the shots you ...   \n",
       "3  Dishes & swishes... buckets & handles... @Step...   \n",
       "4  Donovan Mitchell goes coast to coast to beat t...   \n",
       "\n",
       "                                              tweet2  similarity_label  \n",
       "0               It's morrissey night! Where are you?                 0  \n",
       "1  House Intelligence Committee votes to release ...                 0  \n",
       "2        I mean... I guess I have to give it a shot.                 1  \n",
       "3           My new babies pic.twitter.com/s4ejQD6V4l                 0  \n",
       "4  Had a lot of fun creating The Private Edition ...                 0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1300, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data to lowercasae\n",
    "test_df[\"tweet1\"] = [tweet.lower() for tweet in test_df[\"tweet1\"]]\n",
    "test_df[\"tweet2\"] = [tweet.lower() for tweet in test_df[\"tweet2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters from test data \n",
    "test_df[\"tweet1\"] = [remove_special_chars(tweet) for tweet in test_df[\"tweet1\"]]\n",
    "test_df[\"tweet2\"] = [remove_special_chars(tweet) for tweet in test_df[\"tweet2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize test data\n",
    "tokenized_x_test_tweet1 = [tokenize_text(tokenizer, tweet) for tweet in test_df['tweet1']]\n",
    "tokenized_x_test_tweet2 = [tokenize_text(tokenizer, tweet) for tweet in test_df['tweet2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the input id tensors from the tokenized list of input ids, token ids and attention mask\n",
    "inputs_5=[i['input_ids'] for i in tokenized_x_test_tweet1 ]\n",
    "inputs_6=[i['input_ids'] for i in tokenized_x_test_tweet2 ]\n",
    "\n",
    "# Converting the input id tensors to numpy arrays\n",
    "inputs_5_array = np.array([tensor.numpy() for tensor in inputs_5])\n",
    "inputs_6_array = np.array([tensor.numpy() for tensor in inputs_6])\n",
    "\n",
    "# Ensuring the shapes of inputs_5_array and inputs_6_array are compatible\n",
    "inputs_5_array = inputs_5_array.squeeze(axis=1)\n",
    "inputs_6_array = inputs_6_array.squeeze(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT\n",
    "predictions=model.predict([inputs_5_array,inputs_6_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.50\n",
      "Recall: 1.00\n",
      "F1 Score: 0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Round off predictions\n",
    "predicted_labels=np.round(predictions).astype(int)\n",
    "\n",
    "# Get true labels from test data\n",
    "true_labels=test_df[\"similarity_label\"]\n",
    "\n",
    "# Compute precision, recall and f1-score\n",
    "precision = precision_score(true_labels, predicted_labels)\n",
    "recall = recall_score(true_labels, predicted_labels)\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
